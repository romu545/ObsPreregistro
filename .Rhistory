tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
rbind()
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows()
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows() |>
dplyr::mutate(
'fechas' =
stringr::str_extract_all(
.data$name, "\\b\\d{2}\\s\\w{3}\\s\\d{4}\\b") |>
stringr::str_replace_all(
pattern = c(
" ENE " = "01", " FEB " = "02", " MAR " = "03", " ABR " = "04",
" MAY " = "05", " JUN " = "06", " JUL " = "07", " AGO " = "08",
" SEP " = "09", " OCT " = "10", " NOV " = "11", " DIC " = "12")) |>
lubridate::dmy(),
.keep = "unused")
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows() |>
dplyr::mutate(
'fechas' =
stringr::str_extract_all(
.data$name, "\\b\\d{2}\\s\\w{3}\\s\\d{4}\\b") |>
stringr::str_replace_all(
pattern = c(
" ENE " = "01", " FEB " = "02", " MAR " = "03", " ABR " = "04",
" MAY " = "05", " JUN " = "06", " JUL " = "07", " AGO " = "08",
" SEP " = "09", " OCT " = "10", " NOV " = "11", " DIC " = "12")) |>
lubridate::dmy())
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows() |>
dplyr::mutate(
'fechas' =
stringr::str_extract_all(
.data$name, "\\b\\d{2}\\s\\w{3}\\s\\d{4}\\b") |>
stringr::str_replace_all(
pattern = c(
" ENE " = "01", " FEB " = "02", " MAR " = "03", " ABR " = "04",
" MAY " = "05", " JUN " = "06", " JUL " = "07", " AGO " = "08",
" SEP " = "09", " OCT " = "10", " NOV " = "11", " DIC " = "12")) |>
lubridate::dmy()) |>
dplyr::filter(.data$fechas >= fecha.tracks)
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows() |>
dplyr::mutate(
'fechas' =
stringr::str_extract_all(
.data$name, "\\b\\d{2}\\s\\w{3}\\s\\d{4}\\b") |>
stringr::str_replace_all(
pattern = c(
" ENE " = "01", " FEB " = "02", " MAR " = "03", " ABR " = "04",
" MAY " = "05", " JUN " = "06", " JUL " = "07", " AGO " = "08",
" SEP " = "09", " OCT " = "10", " NOV " = "11", " DIC " = "12")) |>
lubridate::dmy()) |>
dplyr::filter(.data$fechas >= fecha.tracks) |>
sf::st_buffer(buffer)
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows() |>
dplyr::mutate(
'fechas' =
stringr::str_extract_all(
.data$name, "\\b\\d{2}\\s\\w{3}\\s\\d{4}\\b") |>
stringr::str_replace_all(
pattern = c(
" ENE " = "01", " FEB " = "02", " MAR " = "03", " ABR " = "04",
" MAY " = "05", " JUN " = "06", " JUL " = "07", " AGO " = "08",
" SEP " = "09", " OCT " = "10", " NOV " = "11", " DIC " = "12")) |>
lubridate::dmy()) |>
dplyr::filter(.data$fechas >= fecha.tracks) |>
sf::st_buffer(buffer) |>
sf::st_union() |>
sf::st_make_valid()
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows() |>
dplyr::mutate(
'fechas' =
stringr::str_extract_all(
.data$name, "\\b\\d{2}\\s\\w{3}\\s\\d{4}\\b") |>
stringr::str_replace_all(
pattern = c(
" ENE " = "01", " FEB " = "02", " MAR " = "03", " ABR " = "04",
" MAY " = "05", " JUN " = "06", " JUL " = "07", " AGO " = "08",
" SEP " = "09", " OCT " = "10", " NOV " = "11", " DIC " = "12")) |>
lubridate::dmy()) |>
dplyr::filter(.data$fechas >= fecha.tracks) |>
sf::st_buffer(buffer) |>
sf::st_union() |>
sf::st_make_valid() |>
(\(data) {dplyr::filter(!sf::st_is_empty(data))})()
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows() |>
dplyr::mutate(
'fechas' =
stringr::str_extract_all(
.data$name, "\\b\\d{2}\\s\\w{3}\\s\\d{4}\\b") |>
stringr::str_replace_all(
pattern = c(
" ENE " = "01", " FEB " = "02", " MAR " = "03", " ABR " = "04",
" MAY " = "05", " JUN " = "06", " JUL " = "07", " AGO " = "08",
" SEP " = "09", " OCT " = "10", " NOV " = "11", " DIC " = "12")) |>
lubridate::dmy()) |>
dplyr::filter(.data$fechas >= fecha.tracks) |>
sf::st_buffer(buffer) |>
sf::st_union() |>
sf::st_make_valid()
dplyr::filter(tracks.colectores, sf::st_is_empty(tracks.colectores))
tracks.colectores[sf::st_is_empty(tracks.colectores)]
tracks.colectores[!sf::st_is_empty(tracks.colectores)]
tracks.colectores <-
lapply(
dir(ruta.archivos.gpx, full.names = TRUE),
sf::st_read, layer = "tracks") |>
dplyr::bind_rows() |>
dplyr::mutate(
'fechas' =
stringr::str_extract_all(
.data$name, "\\b\\d{2}\\s\\w{3}\\s\\d{4}\\b") |>
stringr::str_replace_all(
pattern = c(
" ENE " = "01", " FEB " = "02", " MAR " = "03", " ABR " = "04",
" MAY " = "05", " JUN " = "06", " JUL " = "07", " AGO " = "08",
" SEP " = "09", " OCT " = "10", " NOV " = "11", " DIC " = "12")) |>
lubridate::dmy()) |>
dplyr::filter(.data$fechas >= fecha.tracks) |>
sf::st_buffer(buffer) |>
sf::st_union() |>
sf::st_make_valid() |>
(\(data) {data[!sf::st_is_empty(data)]})()
rev.pt.fruera.ruta <- sf::st_filter(
datos.evaluar.sf,
sf::st_union(tracks.colectores) |> sf::st_make_valid(),
.predicate = sf::st_disjoint) |>
tibble::as_tibble() |>
dplyr::mutate(
'registro' = .data$registro,
'Observaciones: Coordenadas fuera de ruta' = stringr::str_c(
"Las coordenadas de este registro se encuentran alejadas de la ruta recorrida. ",
"Verificar si existe algún error en las coordenadas o que el archivo GPX cargado",
"corresponde a la semana evaluda.\n",
"RESPUESTA DEL COLECTOR:"),
.keep = "none")
rev.pt.fruera.ruta <- sf::st_filter(
datos.evaluar.sf,
tracks.colectores,
.predicate = sf::st_disjoint) |>
tibble::as_tibble() |>
dplyr::mutate(
'registro' = .data$registro,
'Observaciones: Coordenadas fuera de ruta' = stringr::str_c(
"Las coordenadas de este registro se encuentran alejadas de la ruta recorrida. ",
"Verificar si existe algún error en las coordenadas o que el archivo GPX cargado",
"corresponde a la semana evaluda.\n",
"RESPUESTA DEL COLECTOR:"),
.keep = "none")
View(rev.pt.fruera.ruta)
ggplot() +
geom_sf(data = tracks.colectores) +
geom_sf(data = datos.evaluar.sf, aes(colour = colector))
gc()
sf::st_write(datos.evaluar.sf, "datos.shp", layer = "points")
sf::st_write(datos.evaluar.sf, "datos.shp")
sf::st_write(datos.evaluar.sf, "datos.shp")
sf::st_write(datos.evaluar.sf, "datos.shp")
st_drivers(datos.evaluar.sf)
sf::st_write(datos.evaluar.sf, "datos.shp")
sf::st_write(datos.evaluar.sf, "datos.shp")
datos.evaluar.sf
sf::st_write(datos.evaluar.sf, "datos.shp", layer = "point")
tracks.colectores
sf::st_write(tracks.colectores, "datos_2.shp", layer = "MULTIPOLYGON")
View(rev.pt.fruera.ruta)
rev.pt.fruera.ruta <- sf::st_filter(
datos.evaluar.sf,
tracks.colectores,
.predicate = sf::st_disjoint) |>
tibble::as_tibble() |>
dplyr::mutate(
'registro' = .data$registro,
.data%colector,
rev.pt.fruera.ruta <- sf::st_filter(
datos.evaluar.sf,
tracks.colectores,
.predicate = sf::st_disjoint) |>
tibble::as_tibble() |>
dplyr::mutate(
'registro' = .data$registro,
.data$colector,
'Observaciones: Coordenadas fuera de ruta' = stringr::str_c(
"Las coordenadas de este registro se encuentran alejadas de la ruta recorrida. ",
"Verificar si existe algún error en las coordenadas o que el archivo GPX cargado",
"corresponde a la semana evaluda.\n",
"RESPUESTA DEL COLECTOR:"),
.keep = "none")
devtools::document()
devtools::check()
library(ObsPreregistro)
library(ObsPreregistro)
Semana <- "Semana_43_44"
# Nombre de la carpeta en donde se guardarán los archivos resultantes de la revisión.
Carpeta <- paste0("Revision_", Semana)
# Crear la carpeta que contendrá los archivos resultantes de la revisión. Adicionalmente,
# se creará una subcarpeta para guardar los archivos shape para evaluar las coordenadas
# por fuera de la ruta.
fs::dir_create(file.path(Carpeta, "Shape"))
# Intervalos de registros para revisar.
Registros.Evaluar <- c(20041L, 20234L)
# Ruta de los archivos GPX.
Ruta.Archivos.GPX <- "c:/Users/romu5/OneDrive/Documentos/R/Tracks_S43/"
# Intervalos de registros para revisar.
Registros.Evaluar <- c(20041L, 20234L)
# Ruta de los archivos GPX.
Ruta.Archivos.GPX <- "c:/Users/romu5/OneDrive/Documentos/R/Tracks_S43/"
## Importar todos los datos del informe de pre-registro.
Datos.Preregistro <- D_G_Preregistro("http://sepec.aunap.gov.co/Acuicultura/InformePreregistroCaracterizacionAcuiculturaCSV2.csv")
## Filtrar los pre-registros de la vigencia actual.
Datos.Preregistro.Vigencia.Actual <- Datos.Preregistro |>
dplyr::filter(fechadigitacion > "2023-10-01")
## Filtrar los pre-registros para evaluar.
Datos.Evaluar <- Datos.Preregistro.Vigencia.Actual |>
dplyr::filter(dplyr::between(registro, Registros.Evaluar[1], Registros.Evaluar[2]))
## Filtrar los pre-registros anteriormente evaluados.
Preregistros.Antiguos <- Datos.Preregistro |>
dplyr::filter(colector != "pnud", registro < Registros.Evaluar[1]) |>
dplyr::select(c("registro", "latitud", "longitud"))
Datos.Evaluar.SF <- Datos_Evaluar_SF(Datos.Evaluar)
Dptos.Evaluar <- unique(Datos.Preregistro.Vigencia.Actual[['departamento']])
# Intervalos de registros para revisar.
Registros.Evaluar <- c(20041L, 20234L)
## Importar todos los datos del informe de pre-registro.
Datos.Preregistro <- D_G_Preregistro("http://sepec.aunap.gov.co/Acuicultura/InformePreregistroCaracterizacionAcuiculturaCSV2.csv")
## Filtrar los pre-registros de la vigencia actual.
Datos.Preregistro.Vigencia.Actual <- Datos.Preregistro |>
dplyr::filter(fechadigitacion > "2023-10-01")
## Filtrar los pre-registros para evaluar.
Datos.Evaluar <- Datos.Preregistro.Vigencia.Actual |>
dplyr::filter(dplyr::between(registro, Registros.Evaluar[1], Registros.Evaluar[2]))
## Filtrar los pre-registros anteriormente evaluados.
Preregistros.Antiguos <- Datos.Preregistro |>
dplyr::filter(colector != "pnud", registro < Registros.Evaluar[1]) |>
dplyr::select(c("registro", "latitud", "longitud"))
Datos.Evaluar.SF <- Datos_Evaluar_SF(Datos.Evaluar)
Dptos.Evaluar <- unique(Datos.Preregistro.Vigencia.Actual[['departamento']])
Mpios.Evaluar <- unique(Datos.Preregistro.Vigencia.Actual[['municipio']])
Lista.Nombres.Validos <- utils::read.csv("C:/Users/romu5/OneDrive/Documentos/R/Revision_Preregistro/Nom_UPA.csv")
Lista.Nombres.Auxiliar <- c("la upa no existe", "upa inexistente", "no informa", "no aplica")
Lista.Nombres.Auxiliar <- c("la upa no existe", "upa inexistente", "no informa", "no aplica")
Datos.GC.SF <- D_G_Caracterizacion_SF(
"http://sepec.aunap.gov.co/Acuicultura/CaracterizacionGranjaAcuiculturaCSV2.csv",
Dptos.Evaluar,
Mpios.Evaluar)
Obs.Nombre.UPA <- Obs_Nombre_UPA(Datos.Evaluar, Lista.Nombres.Validos, Lista.Nombres.Auxiliar)
Obs.Nombre.UPA.Inexistente <- Obs_Nombre_UPA_Inexistente(Datos.Evaluar, Lista.Nombres.Auxiliar)
Obs.Nombre.Predio <- Obs_Nombre_Predio(Datos.Evaluar, Lista.Nombres.Auxiliar)
Obs.Codigo.Misma.UPA <- Obs_Codigo_Misma_UPA(Datos.Evaluar, Datos.Preregistro)
Obs.Posibles.UPA.Repetidas <- Obs_Posibles_UPA_Repetidas(Datos.Evaluar, Lista.Nombres.Auxiliar)
Obs.UPA.Repetidas <- Obs_UPA_Repetidas(Datos.Evaluar, Lista.Nombres.Auxiliar)
Obs.Coordenadas.Repetidas <- Obs_Coordenadas_Repetidas(Datos.Evaluar)
Obs.Coordenadas.En.Pregistros.Antiguos <- Obs_Coordenadas_En_Pregistros_Antiguos(Datos.Evaluar, Preregistros.Antiguos)
Datos.Elevacion <- Datos_Elevacion(Datos.Evaluar.SF)
UPA.Asignadas.SF <- readr::read_delim(
"C:/Users/romu5/OneDrive/Documentos/R/Revision_Preregistro/Para_Caracterizar_2023_II.csv",
delim = ";",
show_col_types = FALSE,
progress = FALSE) |>
dplyr::select(
"codigoupa" = "Codigo_UPA",
"departamento" = "Departamento",
"municipio" = "Municipio",
"latitud" = "Latitud",
"longitud" = "Longitud") |>
sf::st_as_sf(coords = c("longitud", "latitud"), crs = 4326)
Obs.Altitudes.UPA <- Obs_Altitudes_UPA(Datos.Elevacion)
Obs.Distancia.Con.UPA.Digitadas <- Obs_Distancia_Con_UPA_Digitadas(Datos.Evaluar.SF, Datos.GC.SF)
Obs.Coordenadas.Preregistro.y.Asignadas <- Obs_Coordenadas_Preregistro_vs_Asignadas(Datos.Evaluar.SF, UPA.Asignadas.SF)
# Ruta de los archivos GPX.
Ruta.Archivos.GPX <- "c:/Users/romu5/OneDrive/Documentos/R/Tracks_S43/"
Obs.Coordenadas.Fuera.Ruta <- Obs_Coordenadas_Fuera_Ruta(Datos.Evaluar.SF, Ruta.Archivos.GPX, "2023-10-17", 20)
Mpio.shp <- sf::st_read("c:/Users/romu5/Downloads/Programas y Material de estudio - QGIS/MGN2021_MPIO_POLITICO/MGN_MPIO_POLITICO.shp") |>
dplyr::select(c("DPTO_CNMBR", "MPIO_CNMBR", "geometry")) |>
sf::st_transform(crs = 4326)
Mpio.shp <- sf::st_read("c:/Users/romu5/OneDrive/SEPEC/MGN_2022/MPIO/MGN_MPIO_POLITICO.shp") |>
dplyr::select(c("DPTO_CNMBR", "MPIO_CNMBR", "geometry")) |>
sf::st_transform(crs = 4326)
Obs.Municipios.Diferentes <- Obs_Municipios_Diferentes(Datos.Evaluar.SF, Mpio.shp)
Mpio.shp <- sf::st_read("c:/Users/romu5/OneDrive/SEPEC/MGN_2022/MPIO/MGN_MPIO_POLITICO.shp") |>
dplyr::select(c("DPTO_CNMBR", "MPIO_CNMBR", "geometry")) |>
sf::st_transform(crs = 4326) |>
sf::st_make_valid()
gc()
Obs.Municipios.Diferentes <- Obs_Municipios_Diferentes(Datos.Evaluar.SF, Mpio.shp)
View(Obs.Municipios.Diferentes)
Datos.Evaluar.SF |> sf::write_sf(file.path(Carpeta, "Shape/Datos_Evaluar.shp"))
Datos.Evaluar.SF |> sf::st_write(file.path(Carpeta, "Shape/Datos_Evaluar.shp"), layer = "point", delete_layer = TRUE)
Datos.Evaluar.SF |> sf::st_write(file.path(Carpeta, "Shape/Datos_Evaluar.shp"), layer = "point", driver = "shape" ,delete_layer = TRUE)
Datos.Evaluar.SF |> sf::st_write(file.path(Carpeta, "Shape/Datos_Evaluar.shp"), layer = "point", driver = ".shp" ,delete_layer = TRUE)
## Exportar la relación general de los pre-registros evaluados.
Relacion.General.Observaciones <- Relacion_General_Observaciones(Datos.Evaluar)
Consolidado_Observaciones <- purrr::reduce(
.x = purrr::list_flatten(list(Datos.Evaluar = Datos.Evaluar, mget(ls(pattern = "Obs\\.", sorted = TRUE, envir = .GlobalEnv), envir = .GlobalEnv))),
.f = \(x, y) dplyr::left_join(x, y, by = c("registro")))
Consolidado_Observaciones
View(Consolidado_Observaciones)
library(ObsPreregistro)
library(ObsPreregistro)
Semana <- "Semana_43_44"
# Nombre de la carpeta en donde se guardarán los archivos resultantes de la revisión.
Carpeta <- paste0("Revision_", Semana)
# Crear la carpeta que contendrá los archivos resultantes de la revisión. Adicionalmente,
# se creará una subcarpeta para guardar los archivos shape para evaluar las coordenadas
# por fuera de la ruta.
fs::dir_create(file.path(Carpeta, "Shape"))
# Intervalos de registros para revisar.
Registros.Evaluar <- c(20041L, 20234L)
# Ruta de los archivos GPX.
Ruta.Archivos.GPX <- "c:/Users/romu5/OneDrive/Documentos/R/Tracks_S43/"
## Importar todos los datos del informe de pre-registro.
Datos.Preregistro <- D_G_Preregistro("http://sepec.aunap.gov.co/Acuicultura/InformePreregistroCaracterizacionAcuiculturaCSV2.csv")
## Filtrar los pre-registros de la vigencia actual.
Datos.Preregistro.Vigencia.Actual <- Datos.Preregistro |>
dplyr::filter(fechadigitacion > "2023-10-01")
## Filtrar los pre-registros para evaluar.
Datos.Evaluar <- Datos.Preregistro.Vigencia.Actual |>
dplyr::filter(dplyr::between(registro, Registros.Evaluar[1], Registros.Evaluar[2]))
## Filtrar los pre-registros anteriormente evaluados.
Preregistros.Antiguos <- Datos.Preregistro |>
dplyr::filter(colector != "pnud", registro < Registros.Evaluar[1]) |>
dplyr::select(c("registro", "latitud", "longitud"))
Datos.Evaluar.SF <- Datos_Evaluar_SF(Datos.Evaluar)
Obs.Coordenadas.Fuera.Ruta <- Obs_Coordenadas_Fuera_Ruta(Datos.Evaluar.SF, Ruta.Archivos.GPX, "2023-10-17", 20)
View(Obs.Coordenadas.Fuera.Ruta)
tools::showNonASCII("ramón Nuñez")
iconv("ramón Nuñez")
iconv("ramón Nuñez", "UTF-8", "ASCII")
iconv("ramón Nuñez",  "LATIN2", "UTF-8")
iconv("ramón Nuñez",  "LATIN1", "UTF-8")
devtools::document()
ObsAcuicultura::URLs_Informes
rio::import("http://sepec.aunap.gov.co/Acuicultura/InformeUPASHabilitadas.csv", format = ";")
habilitadas <- rio::import("http://sepec.aunap.gov.co/Acuicultura/InformeUPASHabilitadas.csv", format = ";")
subset(habilitadas, registro > 20011)
subset(habilitadas, registro > 20011) |> table(colector)
subset(habilitadas, registro > 20011) |> table("colector")
subset(habilitadas, registro > 20011)["colector"]
subset(habilitadas, registro > 20011)["colector"] |> table()
RCurl::url.exists("http://sepec.aunap.gov.co/Acuicultura/CaracterizacionGranjaAcuiculturaCSV2.csv")
RCurl::url.exists("http://sepec.aunap.gov.co/Acuicultura/Datos_Generales_Caracterizacion.csv")
RCurl::url.exists("http://sepec.aunap.gov.co/Acuicultura/Datos_Generales_Caracterizacion4.csv")
RCurl::url.exists("http://sepec.aunap.gov.co/Acuicultura/Datos_Generales_Caracterizacion.csv")
RCurl::getURL("http://sepec.aunap.gov.co/Acuicultura/CaracterizacionGranjaAcuiculturaCSV2.csv")
url_PesoE_Numero_Ejemplares_Kg_IND_Hist<-"https://raw.githubusercontent.com/JesusCuriel21/Tabla_Referencia_Volumen/main/PesoE_Numero_Ejemplares_Kg_IND_Historico.csv"
read_delim(url_PesoE_Numero_Ejemplares_Kg_IND_Hist,
delim = ";", escape_double = FALSE, trim_ws = TRUE)
readr::read_delim(url_PesoE_Numero_Ejemplares_Kg_IND_Hist,
delim = ";", escape_double = FALSE, trim_ws = TRUE)
Umb_PesoE_Numero_Ejemplares_Kg_IND_Hist <- readr::read_delim(url_PesoE_Numero_Ejemplares_Kg_IND_Hist,
delim = ";", escape_double = FALSE, trim_ws = TRUE)# base para calcular el precio por kg del ultimo mes ya verificado
View(Umb_PesoE_Numero_Ejemplares_Kg_IND_Hist)
# base para calcular el precio por kg del ultimo mes ya verificado
Umb_PesoE_Numero_Ejemplares_Kg_IND_Hist <- readr::read_delim(
url_PesoE_Numero_Ejemplares_Kg_IND_Hist,
delim = ";",
escape_double = FALSE,
trim_ws = TRUE,
locale = readr::locale(decimal_mark = ","))
file.path("https://raw.githubusercontent.com/JesusCuriel21/Tabla_Referencia_Volumen", "d")
urltools::domain("https://raw.githubusercontent.com/JesusCuriel21/Tabla_Referencia_Volumen", "d"
urltools::domain("https://raw.githubusercontent.com/JesusCuriel21/Tabla_Referencia_Volumen/main/Base_Volumen_Total_Final.csv")
c(
url_Cat = "Categoria_Volumen_Final.csv",
url_Pre = "Forma%20de%20presentacion_Volumen_Final.csv",
url_Precio_Hist = "Precio_Historico_Vol.csv",
url_PesoE_Numero_Ejemplares_Kg_IND_Hist = "PesoE_Numero_Ejemplares_Kg_IND_Historico.csv",
url_Volumen_Total_Hist = "Base_Volumen_Total_Final.csv",
url_No._UEP_Hist = "No._UEP_Historico.csv"
)
Nom_Archivos <- c(
url_Cat = "Categoria_Volumen_Final.csv",
url_Pre = "Forma%20de%20presentacion_Volumen_Final.csv",
url_Precio_Hist = "Precio_Historico_Vol.csv",
url_PesoE_Numero_Ejemplares_Kg_IND_Hist = "PesoE_Numero_Ejemplares_Kg_IND_Historico.csv",
url_Volumen_Total_Hist = "Base_Volumen_Total_Final.csv",
url_No._UEP_Hist = "No._UEP_Historico.csv"
)
url_base <- "https://raw.githubusercontent.com/JesusCuriel21/Tabla_Referencia_Volumen/main"
file.path(url_base, Nom_Archivos)
url_base <- "https://raw.githubusercontent.com/JesusCuriel21/Tabla_Referencia_Volumen/main"
nom_archivos <- c(
"Categoria_Volumen_Final.csv",
"Forma%20de%20presentacion_Volumen_Final.csv",
"Precio_Historico_Vol.csv",
"PesoE_Numero_Ejemplares_Kg_IND_Historico.csv",
"Base_Volumen_Total_Final.csv",
"No._UEP_Historico.csv"
)
nom_tablas <- c(
"Lcategoria",
"Lpresentacion",
"Umb_precio_Hist",
"Umb_PesoE_Numero_Ejemplares_Kg_IND_Hist",
"Umb_Volumen_Total_Hist",
"Umb_No._UEP_Hist"
)
datos <- lapply(
file.path(url_base, Nom_Archivos),
readr::read_delim,
delim = ";",
escape_double = FALSE,
trim_ws = TRUE,
locale = readr::locale(decimal_mark = ",")) |>
setNames(nom_tablas)
datos <- lapply(
file.path(url_base, nom_archivos),
readr::read_delim,
delim = ";",
escape_double = FALSE,
trim_ws = TRUE,
locale = readr::locale(decimal_mark = ",")) |>
setNames(nom_tablas)
datos <- lapply(
file.path(url_base, nom_archivos),
readr::read_delim,
delim = ";",
escape_double = FALSE,
trim_ws = TRUE,
locale = readr::locale(decimal_mark = ","),
show_col_types = FALSE) |>
setNames(nom_tablas)
View(datos)
datos[["Umb_No._UEP_Hist"]]
View(datos)
View(datos[["Lcategoria"]])
View(datos[["Lpresentacion"]])
View(datos[["Umb_precio_Hist"]])
View(datos[["Umb_Volumen_Total_Hist"]])
View(datos[["Umb_No._UEP_Hist"]])
View(datos[["Umb_PesoE_Numero_Ejemplares_Kg_IND_Hist"]])
View(datos[["Umb_No._UEP_Hist"]])
format.Date("2023-01-02", "%m")
as.integer(format.Date("2023-01-02", "%m"))
as.integer(format("2023-01-02", "%m"))
format("2023-01-02", "%m")
format(as.date("2023-01-02"), "%m")
format(as.Date("2023-01-02"), "%m")
matrix(data = "", nrow = 10, ncol = 1)
a <- data.frame(x = 1:10)
a$y <- matrix(data = "", nrow = 10, ncol = 1)
a
matrix(data = "", nrow = 10, ncol = 7)
library(ObsPreregistro)
datos <- ObsAcuicultura::D_F_Produccion()
datos <- ObsAcuicultura::D_F_Produccion()
datos
datos |> dplyr::filter(Departamento == "Tolima") |> dplyr::count(`Tipo de infraestructura`, Especie)
datos |> dplyr::filter(Departamento == "Tolima", `Tipo de infraestructura` == "Canales en tierra") |> dplyr::count(`Tipo de infraestructura`, Especie)
datos |> dplyr::filter(Departamento == "Tolima", `Tipo de infraestructura` == "Canales en tierra")
datos |> dplyr::filter(Departamento == "Tolima") |> dplyr::count(`Tipo de infraestructura`)
datos |> dplyr::filter(`Tipo de infraestructura` == "Canales en tierra") |> dplyr::count(Departamento)
datos_g <- ObsAcuicultura::D_G_Caracterizacion()
datos_g <- ObsAcuicultura::D_G_Caracterizacion()
table(datos_g$`Estado de la granja`)
datos_g |> dplyr::count(`Estado de la granja`)
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::add_totals_row()
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::add_totals_row(n)
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::adorn_totals()
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::adorn_totals() |> janitor::adorn_percentages("col")
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::adorn_percentages("col")
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::adorn_totals() |> dplyr::mutate(janitor::adorn_percentages("col")
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::adorn_totals() |> dplyr::mutate("%" = janitor::adorn_percentages("col"))
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::adorn_totals() |> dplyr::mutate("%" = janitor::adorn_percentages("col"))
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::adorn_totals()
datos_g |> dplyr::count(`Estado de la granja`) |> janitor::adorn_percentages("col")
iris |> dplyr::reframe(across(Sepal.Length, c("mean", "median")))
iris |> dplyr::reframe(across(Sepal.Length, list("mean", "median")))
iris |> dplyr::reframe(across(Sepal.Length, list(mean(), median())))
iris |> dplyr::reframe(across(Sepal.Length, list(mean(.x), median(.x))))
iris |> dplyr::reframe(across(Sepal.Length, list(mean(.), median(.))))
iris %>%
summarise(across(starts_with("Sepal"), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"), .by = "Species")
iris |>
summarise(across(starts_with("Sepal"), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"), .by = "Species")
library(dplyr)
iris |>
summarise(across(starts_with("Sepal"), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"), .by = "Species")
iris |>
reframe(across(starts_with("Sepal"), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"), .by = "Species")
